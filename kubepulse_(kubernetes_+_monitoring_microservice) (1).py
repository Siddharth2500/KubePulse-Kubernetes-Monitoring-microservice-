# -*- coding: utf-8 -*-
"""KubePulse (Kubernetes + Monitoring microservice)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y1sEyvWd3UiDWmKNrdVAn4E3hqiXSSDK
"""

# ==== KubePulse (clean one-cell setup for Google Colab) ====
# This cell creates /content/kubepulse, writes all files, installs deps, and starts the API.

import os, sys, subprocess, threading, time

PROJECT_ROOT = "/content/kubepulse"
os.makedirs(PROJECT_ROOT, exist_ok=True)

def write(path: str, content: str):
    full = os.path.join(PROJECT_ROOT, path)
    os.makedirs(os.path.dirname(full), exist_ok=True)
    with open(full, "w", encoding="utf-8") as f:
        f.write(content.strip() + "\n")

# ---------------- app/main.py ----------------
write("app/main.py", """
from fastapi import FastAPI, Request
from fastapi.responses import Response, JSONResponse
from pydantic import BaseModel, Field, HttpUrl
import os, time, socket, asyncio
import httpx
from prometheus_client import Counter, Histogram, Gauge, Summary, generate_latest, CONTENT_TYPE_LATEST

APP_NAME = os.getenv("APP_NAME", "KubePulse")
ENV = os.getenv("ENVIRONMENT", "dev")

REQ_COUNT = Counter("kubepulse_http_requests_total", "Total HTTP requests", ["method", "path", "status"])
REQ_LATENCY = Histogram("kubepulse_http_request_duration_seconds", "Request latency seconds", ["method", "path"])
EXTERNAL_PROBE_LATENCY = Summary("kubepulse_external_probe_latency_seconds", "Latency to probe external targets", ["target"])
TASK_QUEUE_GAUGE = Gauge("kubepulse_task_queue_depth", "Example in-memory task queue depth")
UP_GAUGE = Gauge("kubepulse_up", "1 if app is up")

_task_queue_depth = 0
app = FastAPI(title=APP_NAME)

class ProbeRequest(BaseModel):
    url: HttpUrl
    timeout: float = Field(default=3.0, ge=0.1, le=30.0)
    expect_status: int = 200

class LatencyRequest(BaseModel):
    milliseconds: int = Field(default=200, ge=0, le=10000)

@app.on_event("startup")
async def on_startup():
    UP_GAUGE.set(1)

@app.on_event("shutdown")
async def on_shutdown():
    UP_GAUGE.set(0)

@app.middleware("http")
async def metrics_middleware(request: Request, call_next):
    start = time.time()
    response = await call_next(request)
    dur = time.time() - start
    REQ_LATENCY.labels(request.method, request.url.path).observe(dur)
    REQ_COUNT.labels(request.method, request.url.path, str(response.status_code)).inc()
    return response

@app.get("/")
def root():
    return {
        "app": APP_NAME,
        "env": ENV,
        "message": "KubePulse monitoring service",
        "host": socket.gethostname(),
        "tips": ["GET /metrics", "GET /health", "POST /probe", "POST /simulate-latency"]
    }

@app.get("/health")
def health():
    return {"status": "ok"}

@app.get("/ready")
def ready():
    return {"ready": True}

@app.get("/metrics")
def metrics():
    return Response(generate_latest(), media_type=CONTENT_TYPE_LATEST)

@app.post("/probe")
async def probe_target(req: ProbeRequest):
    try:
        async with httpx.AsyncClient(timeout=req.timeout) as client:
            start = time.perf_counter()
            r = await client.get(str(req.url))
            elapsed = time.perf_counter() - start
            EXTERNAL_PROBE_LATENCY.labels(str(req.url)).observe(elapsed)
            ok = (r.status_code == req.expect_status)
            return {
                "target": str(req.url),
                "status_code": r.status_code,
                "ok": ok,
                "latency_seconds": round(elapsed, 4)
            }
    except Exception as e:
        EXTERNAL_PROBE_LATENCY.labels(str(req.url)).observe(req.timeout)
        return JSONResponse(status_code=502, content={"target": str(req.url), "ok": False, "error": str(e)})

@app.post("/simulate-latency")
async def simulate_latency(req: LatencyRequest):
    await asyncio.sleep(req.milliseconds / 1000.0)
    global _task_queue_depth
    _task_queue_depth = max(0, _task_queue_depth - 1)
    TASK_QUEUE_GAUGE.set(_task_queue_depth)
    return {"slept_ms": req.milliseconds, "queue_depth": _task_queue_depth}

@app.post("/enqueue")
def enqueue(n: int = 1):
    global _task_queue_depth
    _task_queue_depth = max(0, _task_queue_depth + max(1, n))
    TASK_QUEUE_GAUGE.set(_task_queue_depth)
    return {"queue_depth": _task_queue_depth}
""")

# ---------------- tests/test_basic.py ----------------
write("tests/test_basic.py", """
from fastapi.testclient import TestClient
from app.main import app

client = TestClient(app)

def test_health_ready():
    assert client.get("/health").json()["status"] == "ok"
    assert client.get("/ready").json()["ready"] is True

def test_enqueue_and_latency():
    before = client.post("/enqueue?n=3").json()["queue_depth"]
    assert before >= 3
""")

# ---------------- requirements.txt ----------------
write("requirements.txt", """
fastapi==0.111.0
uvicorn[standard]==0.30.0
pydantic==1.10.14
prometheus_client==0.20.0
pytest==8.2.1
httpx==0.27.0
""")

# ---------------- Dockerfile ----------------
write("Dockerfile", """
FROM python:3.11-slim
WORKDIR /app
ENV PYTHONDONTWRITEBYTECODE=1 PYTHONUNBUFFERED=1
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
COPY app ./app
EXPOSE 8002
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8002"]
""")

# ---------------- .dockerignore ----------------
write(".dockerignore", """
__pycache__
*.pyc
*.pyo
*.pyd
*.log
.env
.venv
dist
build
.coverage
""")

# ---------------- .gitignore ----------------
write(".gitignore", """
__pycache__/
*.py[cod]
.venv/
.env
dist/
build/
.coverage
pytestcache/
*.log
""")

# ---------------- README.md ----------------
write("README.md", """
# KubePulse â€” Kubernetes + Monitoring Microservice

- Python 3.11, FastAPI
- `/health`, `/ready`, `/metrics`, `/probe`, `/simulate-latency`, `/enqueue`
- Prometheus metrics for requests, latency, probe timing, queue depth

Quick start in Colab:
1) Run the setup cell.
2) Use httpx to call endpoints inside the notebook.
""")

print("âœ… Files written under", PROJECT_ROOT)

# -------- Install deps --------
print("â³ Installing dependencies...")
subprocess.check_call([sys.executable, "-m", "pip", "install", "-r", os.path.join(PROJECT_ROOT, "requirements.txt")])

# -------- Start server (port 8002) --------
import uvicorn, nest_asyncio
nest_asyncio.apply()

def run_server():
    uvicorn.run("app.main:app", host="0.0.0.0", port=8002, reload=False, app_dir=PROJECT_ROOT, log_level="info")

t = threading.Thread(target=run_server, daemon=True)
t.start()
time.sleep(2)

print("\\nðŸš€ KubePulse running at http://127.0.0.1:8002")
try:
    import httpx
    print("GET /health ->", httpx.get("http://127.0.0.1:8002/health", timeout=5).json())
except Exception as e:
    print("Health check failed:", e)